{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a789a492-5621-4dce-a4ac-40cde089ae89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import arcpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f956bbc8-a757-4e3b-b8ac-b30eec6b5cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DirectoryScanner:\n",
    "    \"\"\"A class for scanning directories and processing files and directories.\n",
    "\n",
    "        Args:\n",
    "        path (str): The path to the directory to be scanned.\n",
    "        recursive (bool, optional): Flag indicating whether to scan subdirectories recursively. Defaults to True.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, path: str, recursive: bool = True):\n",
    "        self.path = path\n",
    "        self.recursive = recursive\n",
    "\n",
    "    def parse_result(self, entry: os.DirEntry):\n",
    "        \"\"\"\n",
    "        Parses the given `entry` and returns a `File` or `Directory` object based on the type of entry.\n",
    "\n",
    "        Args:\n",
    "            entry (os.DirEntry): The directory entry to parse.\n",
    "\n",
    "        Returns:\n",
    "            File or Directory: The parsed object representing the entry.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If the entry is neither a file nor a directory.\n",
    "        \"\"\"\n",
    "        if entry.is_file():\n",
    "            return File(\n",
    "                name=entry.name,\n",
    "                path=entry.path,\n",
    "                parent_directory=entry.path.split(entry.name)[0],\n",
    "                extension=entry.name.split(\".\")[-1],\n",
    "                size=round(entry.stat().st_size / 1024000, 2),\n",
    "                created=entry.stat().st_ctime,\n",
    "                modified=entry.stat().st_mtime,\n",
    "                accessed=entry.stat().st_atime,\n",
    "            )\n",
    "        elif entry.is_dir():\n",
    "            return Directory(\n",
    "                name=entry.name,\n",
    "                path=entry.path,\n",
    "                parent_directory=entry.path.split(entry.name)[0],\n",
    "                size=round(entry.stat().st_size / 1024000, 2),\n",
    "                created=entry.stat().st_ctime,\n",
    "                modified=entry.stat().st_mtime,\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"Entry must be a file or directory\")\n",
    "              \n",
    "    def scan(\n",
    "        self,\n",
    "        path: str = None,\n",
    "        recursive: bool = None,\n",
    "        _results: list = None,\n",
    "        _scanned_paths: list = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Scans the specified directory and its subdirectories for files and directories.\n",
    "\n",
    "        Args:\n",
    "            path (str, optional): The path of the directory to scan. If not provided, the default path will be used.\n",
    "            _results (list, optional): A list to store the scan results. If not provided, a new list will be created.\n",
    "            _scanned_paths (list, optional): A list to keep track of the scanned paths. If not provided, a new list will be created.\n",
    "            recursive (bool, optional): Flag indicating whether to scan subdirectories recursively. If not provided, the value specified during object initialization will be used.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of scan results.\n",
    "\n",
    "        Raises:\n",
    "            FileNotFoundError: If the specified directory is not found.\n",
    "            PermissionError: If the user does not have permission to access the directory.\n",
    "        \"\"\"\n",
    "        if _results is None:\n",
    "            _results = []\n",
    "\n",
    "        if _scanned_paths is None:\n",
    "            _scanned_paths = []\n",
    "\n",
    "        if path is None:\n",
    "            path = self.path\n",
    "\n",
    "        if recursive is None:\n",
    "            recursive = self.recursive\n",
    "\n",
    "        try:\n",
    "            print(f\"Scanning {path}\")\n",
    "            for entry in os.scandir(path):\n",
    "                if entry.path not in _scanned_paths:\n",
    "                    _scanned_paths.append(entry.path)\n",
    "                    if entry.is_file():\n",
    "                        _results.append(self.parse_result(entry))\n",
    "                    # If the entry is a directory, scan it.\n",
    "                    elif entry.is_dir():\n",
    "                        # If the entry is not a special directory, scan it.\n",
    "                        if \"$\" in entry.name:\n",
    "                            pass\n",
    "                        if self.recursive:\n",
    "                            _results.append(self.parse_result(entry))\n",
    "                            self.scan(\n",
    "                                path=entry.path,\n",
    "                                _results=_results,\n",
    "                                _scanned_paths=_scanned_paths,\n",
    "                            )\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(\"The specified directory was not found.\")\n",
    "        except PermissionError:\n",
    "            print(\"You do not have permission to access this directory.\")\n",
    "\n",
    "        return _results\n",
    "\n",
    "    @property\n",
    "    def path(self):\n",
    "        \"\"\"\n",
    "        str: The path to the directory to be scanned.\n",
    "        \"\"\"\n",
    "        return self._path\n",
    "\n",
    "    @path.setter\n",
    "    def path(self, value):\n",
    "        \"\"\"\n",
    "        Setter for the path property.\n",
    "\n",
    "        Args:\n",
    "            value (str): The path to be set.\n",
    "\n",
    "        Raises:\n",
    "            FileNotFoundError: If the specified path does not exist.\n",
    "            ValueError: If the specified path is not a directory.\n",
    "        \"\"\"\n",
    "        if not os.path.exists(value):\n",
    "            raise FileNotFoundError(\"Path does not exist\")\n",
    "        if not os.path.isdir(value):\n",
    "            raise ValueError(\"Path must be a directory\")\n",
    "        self._path = value\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f705a2bd-8732-4b73-bc97-141e6046e35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass\n",
    "class File:\n",
    "    \"\"\"A class for storing data about a file.\"\"\"\n",
    "\n",
    "    name: str\n",
    "    path: str\n",
    "    size: str\n",
    "    created: int\n",
    "    modified: str\n",
    "    extension: str\n",
    "    parent_directory: str\n",
    "    accessed: str\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Directory:\n",
    "    name: str\n",
    "    path: str\n",
    "    size: str\n",
    "    created: int\n",
    "    modified: str\n",
    "    parent_directory: str\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class APRXLayer:\n",
    "    name: str\n",
    "    source: str = None\n",
    "    connection: dict = None\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class APRXMap:\n",
    "    name: str\n",
    "    layers: list[APRXLayer]\n",
    "\n",
    "@dataclass\n",
    "class GeodatabaseData:\n",
    "    name: str\n",
    "    type: str\n",
    "    features: int\n",
    "    fields: list[str]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Dataset:\n",
    "    name: str\n",
    "    data: list[GeodatabaseData]\n",
    "\n",
    "@dataclass\n",
    "class APRX(File):\n",
    "    name: str\n",
    "    maps: list[APRXMap]\n",
    "\n",
    "@dataclass\n",
    "class FileGeodatabase(File):\n",
    "    datasets: list[Dataset]\n",
    "    data: list[GeodatabaseData]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Shapefile(File):\n",
    "    features: int\n",
    "    fields: list[str]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420d87a3-34f0-4953-a65a-07128e9f4390",
   "metadata": {},
   "outputs": [],
   "source": [
    "SHAPEFILE_EXTS = [\n",
    "    \".shp\",\n",
    "    \".shx\",\n",
    "    \".dbf\",\n",
    "    \".sbn\",\n",
    "    \".sbx\",\n",
    "    \".fbn\",\n",
    "    \".fbx\",\n",
    "    \".ain\",\n",
    "    \".aih\",\n",
    "    \".atx\",\n",
    "    \".ixs\",\n",
    "    \".mxs\",\n",
    "    \".prj\",\n",
    "    \".xml\",\n",
    "    \".cpg\",\n",
    "    \".shp.xml\",\n",
    "    \".shp.ea.iso.xml\",\n",
    "    \".shp.iso.xml\",\n",
    "]\n",
    "\n",
    "class GeoScanner(DirectoryScanner):\n",
    "    \"\"\"Derived class that processes files.\n",
    "\n",
    "    Args:\n",
    "        path (str): The path to the directory to be scanned.\n",
    "        recursive (bool, optional): Flag indicating whether to scan subdirectories recursively. Defaults to True.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, path: str, recursive: bool = True):\n",
    "        super().__init__(path, recursive)\n",
    "\n",
    "    def process_shapefile(self, file: File):\n",
    "        \"\"\"Processes a shapefile.\n",
    "\n",
    "        Args:\n",
    "            file (File): The shapefile to be processed.\n",
    "\n",
    "        Returns:\n",
    "            Shapefile: The processed shapefile.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If the file is not a shapefile.\n",
    "\n",
    "        \"\"\"\n",
    "        if file.extension != \"shp\":\n",
    "            raise ValueError(\"File must be a shapefile\")\n",
    "\n",
    "        # Finding the basename\n",
    "        basename = file.name.split(\".shp\")[0]\n",
    "        \n",
    "        # Finding related shapefile parts\n",
    "        parent_scan = DirectoryScanner(file.parent_directory).scan(\n",
    "            recursive=False, _results=[]\n",
    "        )\n",
    "        related_files = [\n",
    "            file\n",
    "            for file in parent_scan\n",
    "            if isinstance(file, File)\n",
    "            and basename in file.name\n",
    "            and any([file.name.endswith(ext) for ext in SHAPEFILE_EXTS])\n",
    "        ]\n",
    "\n",
    "        size = sum([file.size for file in related_files])\n",
    "        features = int(str(arcpy.management.GetCount(file.path)))\n",
    "        fields = [field.name for field in arcpy.ListFields(file.path)]\n",
    "\n",
    "        info = file.__dict__ | {\n",
    "            \"size\": size,\n",
    "            \"features\": features,\n",
    "            \"fields\": fields,\n",
    "        }\n",
    "\n",
    "        return Shapefile(**info)\n",
    "\n",
    "    def process_aprx(self, file: File):\n",
    "        \"\"\"Processes an ArcGIS Pro project file.\n",
    "\n",
    "        Args:\n",
    "            file (File): The ArcGIS Pro project file to be processed.\n",
    "\n",
    "        Returns:\n",
    "            APRX: The processed ArcGIS Pro project.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If the file is not an ArcGIS Pro project.\n",
    "\n",
    "        \"\"\"\n",
    "        if file.extension != \"aprx\":\n",
    "            raise ValueError(\"File must be an ArcGIS Pro project\")\n",
    "\n",
    "        aprx = arcpy.mp.ArcGISProject(file.path)\n",
    "\n",
    "        maps = []\n",
    "\n",
    "        for aprx_map in aprx.listMaps():\n",
    "            map_layers = []\n",
    "            for map_layer in aprx_map.listLayers():\n",
    "                if map_layer.isFeatureLayer:\n",
    "                    source = map_layer.dataSource\n",
    "                    connection = map_layer.connectionProperties\n",
    "                else:\n",
    "                    source = None\n",
    "                    connection = None\n",
    "                map_layers.append(\n",
    "                    APRXLayer(\n",
    "                        name=map_layer.name,\n",
    "                        source=source,\n",
    "                        connection=connection,\n",
    "                    )\n",
    "                )\n",
    "            maps.append(\n",
    "                APRXMap(\n",
    "                    name=aprx_map.name,\n",
    "                    layers=map_layers,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return APRX(\n",
    "            **file.__dict__,\n",
    "            maps=maps,\n",
    "        )\n",
    "\n",
    "    def process_file_geodatabase(self, directory: Directory):\n",
    "        \"\"\"Processes a file geodatabase.\n",
    "\n",
    "        Args:\n",
    "            directory (Directory): The file geodatabase directory to be processed.\n",
    "\n",
    "        Returns:\n",
    "            FileGeodatabase: The processed file geodatabase.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If the directory is not a file geodatabase.\n",
    "\n",
    "        \"\"\"\n",
    "        if not directory.name.endswith(\".gdb\"):\n",
    "            raise ValueError(\"File must be a file geodatabase\")\n",
    "\n",
    "        root_data = self.process_datasets(\n",
    "            path=directory.path,\n",
    "        )\n",
    "\n",
    "        arcpy.env.workspace = directory.path\n",
    "\n",
    "        datasets = arcpy.ListDatasets(\"*\", \"All\")\n",
    "\n",
    "        for table in arcpy.ListTables(\"*\", \"All\"):\n",
    "            root_data.append(\n",
    "                GeodatabaseData(\n",
    "                    name=table,\n",
    "                    type=\"Table\",\n",
    "                    features=int(str(arcpy.management.GetCount(table))),\n",
    "                    fields=[field.name for field in arcpy.ListFields(table)],\n",
    "                )\n",
    "            )\n",
    "        datasets = []\n",
    "\n",
    "        # https://pylint.readthedocs.io/en/latest/user_guide/messages/warning/modified-iterating-list.html\n",
    "        for dataset in datasets.copy():\n",
    "            datasets.append(\n",
    "                Dataset(\n",
    "                    name=dataset,\n",
    "                    data=self.process_datasets(\n",
    "                        path=directory.path,\n",
    "                        dataset=dataset,\n",
    "                    ),\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return FileGeodatabase(\n",
    "            **directory.__dict__,\n",
    "            datasets=datasets,\n",
    "            data=root_data,\n",
    "            extension=None,\n",
    "            accessed=None,\n",
    "        )\n",
    "\n",
    "    def process_datasets(self, path: str, dataset: str = None):\n",
    "        \"\"\"Processes datasets within a file geodatabase.\n",
    "\n",
    "        Args:\n",
    "            path (str): The path to the file geodatabase.\n",
    "            dataset (str, optional): The name of the dataset within the file geodatabase. Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of processed datasets.\n",
    "\n",
    "        \"\"\"\n",
    "        data_in_dataset = []\n",
    "        arcpy.env.workspace = path\n",
    "\n",
    "        for feature_class in arcpy.ListFeatureClasses(\"*\", \"All\", dataset):\n",
    "            data_in_dataset.append(\n",
    "                GeodatabaseData(\n",
    "                    name=feature_class,\n",
    "                    type=\"Feature Class\",\n",
    "                    features=int(str(arcpy.management.GetCount(feature_class))),\n",
    "                    fields=[field.name for field in arcpy.ListFields(feature_class)],\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return data_in_dataset\n",
    "    \n",
    "    def geoscan(self):\n",
    "        \"\"\"Scans the directory for geospatial files and processes them.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of processed geospatial files.\n",
    "\n",
    "        \"\"\"\n",
    "        scan_results = self.scan(self.path, self.recursive)\n",
    "        geoscan_results = []\n",
    "        for result in scan_results:\n",
    "            if isinstance(result, File):\n",
    "                if result.extension == \"shp\":\n",
    "                    geoscan_results.append(self.process_shapefile(result))\n",
    "                elif result.extension == \"aprx\":\n",
    "                    geoscan_results.append(self.process_aprx(result))\n",
    "            elif isinstance(result, Directory):\n",
    "                if result.name.endswith(\".gdb\"):\n",
    "                    geoscan_results.append(self.process_file_geodatabase(result))\n",
    "        return geoscan_results    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e2a0d9-db1d-4e2b-ad86-017e930ed46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scanner = GeoScanner(r\".\\data\")\n",
    "results = scanner.geoscan()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb7e16a",
   "metadata": {},
   "source": [
    "Copyright 2025 Esri"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
